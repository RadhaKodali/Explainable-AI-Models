# Explainable-AI-Models
Infertility has a considerable impact on individuals' quality of life, affecting them socially and psychologically, with projections indicating a rise  in the upcoming years. In vitro fertilization (IVF) emerges as one of the primary techniques within economically developed nations, employed to address the rising problem of low fertility. Expert embryologists conventionally grade embryos by reviewing blastocyst images to select the most optimal for transfer, yet this process is time-consuming and lacks efficiency. Blastocyst images provide a valuable resource for assessing embryo viability. In this study, we introduce an explainable artificial intelligence (XAI) framework for classifying embryos, employing a fusion of convolutional neural network (CNN) and long short-term memory (LSTM) architecture, referred to as CNN-LSTM. Utilizing deep learning, our model achieves high accuracy in embryo classification while maintaining interpretability through XAI. To enhance the robustness of blastocyst images, data augmentation techniques are utilized, while feature extraction is facilitated through CNN-LSTM architecture. The model is designed as a binary classifier, distinguishing between two classes: good and poor embryos. The XAI approach employed is local interpretable model-agnostic explanations (LIME), enabling the visualization of the modelâ€™s decision-making process..

MATLAB code for LIME-based interpretation of CNN-LSTM models used in embryo selection for IVF treatment. This repository provides scripts to analyze and visualize model predictions, enhancing transparency and understanding of the decision-making process in IVF embryo assessment. 
